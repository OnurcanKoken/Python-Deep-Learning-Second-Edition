{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_iris_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFsDynFWl9TCLV2F08CVeO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2skA9YAsdhEM",
        "colab_type": "text"
      },
      "source": [
        "Introduction to PyTorch\n",
        "\n",
        "Simple neural network example\n",
        "that classify the Iris flower dataset.\n",
        "\n",
        "I have put the iris.csv dataset, which contains 150 x 5 data and 3 different classes, in Chapter01 file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BfUxHsDexp_",
        "colab_type": "text"
      },
      "source": [
        "Connect your google colab runtime to your Google Drive,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSdLYS-MdhhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # do not use any space to indicate name of a file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRpq8DUWfEuf",
        "colab_type": "text"
      },
      "source": [
        "Set current directory to necessary path,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7pX2TAyDuSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0f6cb3d-9318-4d82-89ae-84efe6e9bf28"
      },
      "source": [
        "cd drive/My\\ Drive/Machine\\ Learning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Machine Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VlINsdGfdOT",
        "colab_type": "text"
      },
      "source": [
        "Check current directory,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS-iYTtWD0GA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5bc22ee-c5f4-4257-dc7f-097be3f4d297"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Machine Learning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQOYEUiEfrB2",
        "colab_type": "text"
      },
      "source": [
        "Check what we have,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcVzJYEcFVOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVndOa3YfuJB",
        "colab_type": "text"
      },
      "source": [
        "Clone the repository to current file if it does not exit there,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yikVWQeHFZFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/OnurcanKoken/Python-Deep-Learning-Second-Edition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AU8ybF-f6Tf",
        "colab_type": "text"
      },
      "source": [
        "Go to Chapter01 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9kWNe0nRJv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "099ad8c7-13ae-4a81-e8d0-5b04e81860f4"
      },
      "source": [
        "cd Python-Deep-Learning-Second-Edition/Chapter01/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Machine Learning/Python-Deep-Learning-Second-Edition/Chapter01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYwKUebdgBY7",
        "colab_type": "text"
      },
      "source": [
        "Classify the Iris flower dataset,\n",
        "\n",
        "The original code gives an error here, pd.read_csv() gets an .csv format dataset but there exist .data file, so I downloaded and changed file format as .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXMAaV_sGKKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('iris.csv',\n",
        "                      names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
        "# originally; \n",
        "# dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
        "#                       names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL4kNU4jIBrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['species'] = pd.Categorical(dataset['species']).codes\n",
        "\n",
        "dataset = dataset.sample(frac=1, random_state=1234)\n",
        "\n",
        "# flower properties/flower class\n",
        "# 120 samples for training\n",
        "# 30 samples for testing\n",
        "\n",
        "train_input = dataset.values[:120, :4]\n",
        "train_target = dataset.values[:120, 4]\n",
        "\n",
        "test_input = dataset.values[120:, :4]\n",
        "test_target = dataset.values[120:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prssFme1oRUm",
        "colab_type": "text"
      },
      "source": [
        "Feedforward network with one hidden layer with five units,\n",
        "\n",
        "A ReLU activation function\n",
        "\n",
        "An output layer with three units\n",
        "\n",
        "\n",
        "*   Has three units\n",
        "*   Each unit corresponds to one of the three classes of Iris flower\n",
        "\n",
        "One-hot encoding for the target data will be used which means each class of the flower will be represented as an array\n",
        "\n",
        "Iris Setosa = [1, 0, 0]; Iris Versicolour = [0, 1, 0]; Iris Virginica = [0, 0, 1]\n",
        "\n",
        "One element of the array will be the target for one unit of the output layer. When the network classifies a new sample, we'll determine the class by taking the unit with the highest activation value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDXa6JukGRwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define first neural network\n",
        "\n",
        "import torch\n",
        "\n",
        "# enables us to use the same random data \n",
        "# every time for the reproducibility of results\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "hidden_units = 5\n",
        "\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(4, hidden_units),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(hidden_units, 3)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKmCjtNlxFlv",
        "colab_type": "text"
      },
      "source": [
        "Loss funtion will measure how different the output of the network is compared to the target data.\n",
        "\n",
        "Stochastic Gradient Descent optimizer with a learning rate of 0.1 and a momentum of 0.9. The SGD is a variation of the gradient descent algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRx2O3cGUY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose optimizer and loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() # loss function\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEUQGlKZG-b2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "ebc955e6-5903-4403-fdcb-91e22e2309f9"
      },
      "source": [
        "# train\n",
        "epochs = 50 # iterate 50 times over the training dataset\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # create the torch variable from numpy arrays\n",
        "    inputs = torch.autograd.Variable(torch.Tensor(train_input).float())\n",
        "    targets = torch.autograd.Variable(torch.Tensor(train_target).long())\n",
        "\n",
        "    # to prevent accumulation from the previous iterations\n",
        "    # since we feed the training data to the neural network net (input)\n",
        "    # and we compute the loss funtion criterion(out, target)\n",
        "    # between the network output and the target data\n",
        "    optimizer.zero_grad() \n",
        "    # propagete the loss value back through the network\n",
        "    # so that we can calculate \n",
        "    # how each network weight affects the loss function\n",
        "    out = net(inputs)\n",
        "    loss = criterion(out, targets)\n",
        "    loss.backward()\n",
        "    # optimizer updates the weights of the network\n",
        "    # to reduce the future loss function values\n",
        "    optimizer.step() \n",
        "\n",
        "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
        "        print('Epoch %d Loss: %.4f' % (epoch + 1, loss.data))\n",
        "# originally;\n",
        "#   if epoch == 0 or (epoch + 1) % 10 == 0:\n",
        "#       print('Epoch %d Loss: %.4f' % (epoch + 1, loss.data[0]))\n",
        "# I have changed because: https://stackoverflow.com/questions/56483122/indexerror-invalid-index-of-a-0-dim-tensor-use-tensor-item-to-convert-a-0-di"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss: 1.2181\n",
            "Epoch 10 Loss: 0.6745\n",
            "Epoch 20 Loss: 0.2447\n",
            "Epoch 30 Loss: 0.1397\n",
            "Epoch 40 Loss: 0.1001\n",
            "Epoch 50 Loss: 0.0855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMhOw4Or3hsE",
        "colab_type": "text"
      },
      "source": [
        "Final Accuracy of our model\n",
        "\n",
        "Feeding the test set to the network and computing the error manually,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru55gPRSGYfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e002465-b9df-459b-b905-c9e7d3db6787"
      },
      "source": [
        "\n",
        "# test\n",
        "import numpy as np\n",
        "\n",
        "inputs = torch.autograd.Variable(torch.Tensor(test_input).float())\n",
        "targets = torch.autograd.Variable(torch.Tensor(test_target).long())\n",
        "\n",
        "optimizer.zero_grad()\n",
        "out = net(inputs)\n",
        "_, predicted = torch.max(out.data, 1)\n",
        "\n",
        "error_count = test_target.size - np.count_nonzero((targets == predicted).numpy())\n",
        "print('Errors: %d; Accuracy: %d%%' % (error_count, 100 * torch.sum(targets == predicted) / test_target.size))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Errors: 0; Accuracy: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIEx5IUX35i1",
        "colab_type": "text"
      },
      "source": [
        "We were able to classify only 30 test samples and all correct.\n",
        "\n",
        "We must keep in mind trying different hyperparameters of the network and see how the accuracy and loss function work.\n",
        "We can try to change the number of units in the hidden layer, the number of epochs we train in the network, as well as the learning rate."
      ]
    }
  ]
}